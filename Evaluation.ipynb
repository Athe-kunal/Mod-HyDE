{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('all_text_ans.json')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in data.items():\n",
    "    if len(v.split(\"<END>\")) != 1001:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD VECTOR DATABASE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"mod_hyde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "def split_text_langchain(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        # Set a really small chunk size, just to show.\n",
    "        # separators = [\". \"],\n",
    "        chunk_size=2000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False)\n",
    "\n",
    "    splitted_text = text_splitter.split_text(text)\n",
    "    return splitted_text\n",
    "\n",
    "pubmed_documents = []\n",
    "\n",
    "with open(\"data/pubmed_subset.txt\",\"r\") as f:\n",
    "    pubmed_text = f.read()\n",
    "pubmed_documents.extend([Document(page_content=pt,metadata={\"source\":\"pubmed\"})for pt in pubmed_text.split(\"<END>\")[:-1]])\n",
    "\n",
    "wikipedia_documents = []\n",
    "with open(\"data/wikipedia_filtered.txt\",\"r\") as f:\n",
    "    wiki_data = f.read()\n",
    "wiki_data_list = wiki_data.split(\"-----------\")[:-1]\n",
    "wiki_data_list = [at.strip() for at in wiki_data_list]\n",
    "all_text_list = []\n",
    "for text in wiki_data_list:\n",
    "    splitted_text = split_text_langchain(text)\n",
    "    all_text_list.extend(splitted_text)\n",
    "wikipedia_documents.extend([Document(page_content=wt,metadata={\"source\":\"wiki\"})for wt in all_text_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name, decoding_type,format_or_not,rank, checkpoint\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "TOP_K = 2\n",
    "pubmed_bm25_retriever = BM25Retriever.from_documents(pubmed_documents,k=TOP_K)\n",
    "# pubmed_bm25_docs = pubmed_bm25_retriever.invoke(question.lower())\n",
    "\n",
    "wiki_bm25_retriever = BM25Retriever.from_documents(wikipedia_documents,k=TOP_K)\n",
    "# wiki_bm25_docs = wiki_bm25_retriever.invoke(question.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions(path):\n",
    "    with open(path,\"r\") as f:\n",
    "        questions = f.readlines()\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_formatted_questions = get_questions(\"data/pubmed_formatted_qs.txt\")\n",
    "pubmed_questions = get_questions(\"data/pubmed_qs.txt\")\n",
    "\n",
    "wikipedia_formatted_question = get_questions(\"data/wikipedia_formatted_qs.txt\")\n",
    "wikipedia_questions = get_questions(\"data/wikipedia_qs.txt\")\n",
    "pubmed_checkpoints = ['561','1122','1683']\n",
    "wikipedia_checkpoints = ['831','1662','2493']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer_pair(dataset_name:str,decoding_type:str,format_or_not:bool,checkpoint:str,rank:str):\n",
    "    assert dataset_name in ['pubmed','wikipedia'], \"Dataset name must be pubmed or wikipedia\"\n",
    "    assert decoding_type in ['greedy','nucleus'], \"Decoding type must be nucleus or greedy\"\n",
    "    assert format_or_not in [True,False], \"Format or not must be True or False\"\n",
    "    if dataset_name == 'pubmed':\n",
    "        assert checkpoint in pubmed_checkpoints, \"The valid checkpoints for Pubmed are ['561','1122','1683']\"\n",
    "    elif dataset_name == 'wikipedia':\n",
    "        assert checkpoint in wikipedia_checkpoints, \"The valid checkpoints for Wikipedia are ['831','1662','2493']\"\n",
    "    assert rank in ['8','32','128']\n",
    "    for key,text in data.items():\n",
    "        if format_or_not:\n",
    "            if \"formatted\" in key:\n",
    "                if decoding_type in key and checkpoint in key and f\"_{rank}_\" in key:\n",
    "                    if dataset_name  == \"pubmed\":\n",
    "                        answers_list = text.split(\"<END>\")[:-1]\n",
    "                        assert len(pubmed_formatted_questions) == len(answers_list), f\"Pubmed: {len(pubmed_formatted_questions)} != {len(answers_list)}\"\n",
    "                        return zip(pubmed_formatted_questions,answers_list)\n",
    "                    if dataset_name  == \"wikipedia\":\n",
    "                        answers_list = text.split(\"<END>\")[:-1]\n",
    "                        assert len(wikipedia_formatted_question) == len(answers_list), f\"Pubmed: {len(wikipedia_formatted_question)} != {len(answers_list)}\"\n",
    "                        return zip(wikipedia_formatted_question,answers_list)\n",
    "        elif not format_or_not:\n",
    "                if decoding_type in key and checkpoint in key and f\"_{rank}_\" in key:\n",
    "                    if dataset_name  == \"pubmed\":\n",
    "                        answers_list = text.split(\"<END>\")[:-1]\n",
    "                        assert len(pubmed_questions) == len(answers_list), f\"Pubmed: {len(pubmed_questions)} != {len(answers_list)}\"\n",
    "                        return zip(pubmed_questions,answers_list)\n",
    "                    if dataset_name  == \"wikipedia\":\n",
    "                        answers_list = text.split(\"<END>\")[:-1]\n",
    "                        assert len(wikipedia_questions) == len(answers_list), f\"Pubmed: {len(wikipedia_questions)} != {len(answers_list)}\"\n",
    "                        return zip(wikipedia_questions,answers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do mitochondria play a role in remodelling lace plant leaves during programmed cell death?\n",
      "\n",
      "We examined whether mitochondria can control the programmed cell death of leaf fibers, using microsurgical surgical techniques and tissue culture. We collected 107 fresh leaves from various plants of the lace plant, which were then cut, fixed and placed on a cover sheet. Sixty of the leaves were used in in situ cell death assay (in vitro) under standard circumstances and sixteen were used in live plant culture. Mitochondria were detected with the flow cytometry technique. The\n",
      "\n",
      "[Document(page_content='Programmed cell death (PCD) is the regulated death of cells within an organism. The lace plant (Aponogeton madagascariensis) produces perforations in its leaves through PCD. The leaves of the plant consist of a latticework of longitudinal and transverse veins enclosing areoles. PCD occurs in the cells at the center of these areoles and progresses outwards, stopping approximately five cells from the vasculature. The role of mitochondria during PCD has been recognized in animals; however, it has been less studied during PCD in plants. The following paper elucidates the role of mitochondrial dynamics during developmentally regulated PCD in vivo in A. madagascariensis. A single areole within a window stage leaf (PCD is occurring) was divided into three areas based on the progression of PCD; cells that will not undergo PCD (NPCD), cells in early stages of PCD (EPCD), and cells in late stages of PCD (LPCD). Window stage leaves were stained with the mitochondrial dye MitoTracker Red CMXRos and examined. Mitochondrial dynamics were delineated into four categories (M1-M4) based on characteristics including distribution, motility, and membrane potential (ΔΨm). A TUNEL assay showed fragmented nDNA in a gradient over these mitochondrial stages. Chloroplasts and transvacuolar strands were also examined using live cell imaging. The possible importance of mitochondrial permeability transition pore (PTP) formation during PCD was indirectly examined via in vivo cyclosporine A (CsA) treatment. This treatment resulted in lace plant leaves with a significantly lower number of perforations compared to controls, and that displayed mitochondrial dynamics similar to that of non-PCD cells. Results depicted mitochondrial dynamics in vivo as PCD progresses within the lace plant, and highlight the correlation of this organelle with other organelles during developmental PCD. To the best of our knowledge, this is the first report of mitochondria and chloroplasts moving on transvacuolar strands to form a ring structure surrounding the nucleus during developmental PCD. Also, for the first time, we have shown the feasibility for the use of CsA in a whole plant system. Overall, our findings implicate the mitochondria as playing a critical and early role in developmentally regulated PCD in the lace plant.\\n', metadata={'source': 'pubmed'}), Document(page_content='\\nThe hypothesis was tested that pectin content and methylation degree participate in regulation of cell wall mechanical properties and in this way may affect tissue growth and freezing resistance over the course of plant cold acclimation and de-acclimation. Experiments were carried on the leaves of two double-haploid lines of winter oil-seed rape (Brassica napus subsp. oleifera), differing in winter survival and resistance to blackleg fungus (Leptosphaeria maculans). Plant acclimation in the cold (2 degrees C) brought about retardation of leaf expansion, concomitant with development of freezing resistance. These effects were associated with the increases in leaf tensile stiffness, cell wall and pectin contents, pectin methylesterase (EC 3.1.1.11) activity and the low-methylated pectin content, independently of the genotype studied. However, the cold-induced modifications in the cell wall properties were more pronounced in the leaves of the more pathogen-resistant genotype. De-acclimation promoted leaf expansion and reversed most of the cold-induced effects, with the exception of pectin methylesterase activity. The results show that the temperature-dependent modifications in pectin content and their methyl esterification degree correlate with changes in tensile strength of a leaf tissue, and in this way affect leaf expansion ability and its resistance to freezing and to fungus pathogens.\\n', metadata={'source': 'pubmed'})]\n",
      "[Document(page_content='Bagian first flew on the crew of STS-29, which launched from Kennedy Space Center, Florida, aboard the Orbiter Discovery, on March 13, 1989. During this highly successful five-day mission, the crew deployed a Tracking and Data Relay Satellite and performed numerous secondary experiments, including a Space Station -heat pipe\" radiator experiment, two student experiments, a protein crystal growth experiment, and a chromosome and plant cell division experiment. Bagian was the principal investigator and performed Detailed Supplementary Objective 470 which described, by the use of transcranial Doppler, the changes of cerebral blood flow and its relationship to Space Adaptation Syndrome (SAS) and Space Motion Sickness (SMS). Bagian was the first person to treat SMS with the drug Phenergan by intramuscular injection. This represented the first successful treatment regimen for SMS and has now been adopted by NASA as the standard of care for the control of SMS in Shuttle crews and is routinely used. In addition, the crew took over 3,000 photographs of the Earth using several types of cameras, including the IMAX 70 mm movie camera. Mission duration was 80 orbits and concluded with a landing at Edwards Air Force Base, California, on March 18, 1989. With the completion of this mission, he logged over 119 hours in space.', metadata={'source': 'wiki'}), Document(page_content=\"The conjugate base of oxalic acid is the hydrogenoxalate anion, and its conjugate base (oxalate) is a competitive inhibitor of the lactate dehydrogenase (LDH) enzyme. LDH catalyses the conversion of pyruvate to lactic acid (end product of the fermentation (anaerobic) process) oxidising the coenzyme NADH to NAD+ and H+ concurrently. Restoring NAD+ levels is essential to the continuation of anaerobic energy metabolism through glycolysis. As cancer cells preferentially use anaerobic metabolism (see Warburg effect) inhibition of LDH has been shown to inhibit tumor formation and growth, thus is an interesting potential course of cancer treatment.\\nOxalic acid plays a key role in the interaction between pathogenic fungi and plants. Small amounts of oxalic acid enhances plant resistance to fungi, but higher amounts cause widespread programmed cell death of the plant and help with fungi infection. Plants normally produce it in small amounts, but some pathogenic fungi such as Sclerotinia sclerotiorum cause a toxic accumulation.Oxalate, besides being biosynthesised, may also be biodegraded. Oxalobacter formigenes is an important gut bacterium that helps animals (including humans) degrade oxalate.\\nOxalic acid's main applications include cleaning or bleaching, especially for the removal of rust (iron complexing agent). Its utility in rust removal agents is due to its forming a stable, water-soluble salt with ferric iron, ferrioxalate ion. Oxalic acid is an ingredient in some tooth whitening products. About 25% of produced oxalic acid is used as a mordant in dyeing processes. It is also used in bleaches, especially for pulpwood, cork, straw, cane, feathers, and for rust removal and other cleaning, in baking powder, and as a third reagent in silica analysis instruments.\", metadata={'source': 'wiki'})]\n"
     ]
    }
   ],
   "source": [
    "zipped_elem = question_answer_pair(\"pubmed\",\"nucleus\",False,'1122','128')\n",
    "for q,a in zipped_elem:\n",
    "    print(q)\n",
    "    print(a)\n",
    "    pubmed_bm25_docs = pubmed_bm25_retriever.invoke(a.lower())\n",
    "    wiki_bm25_docs = wiki_bm25_retriever.invoke(a)\n",
    "    print(pubmed_bm25_docs)\n",
    "    print(wiki_bm25_docs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUBMED EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}\n",
    "{\"custom_id\": \"request-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an unhelpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "llm = dspy.OpenAI(model=\"gpt-3.5-turbo-0125\",max_tokens = 1000)\n",
    "dspy.settings.configure(lm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubMedGenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions in detail based on the context.\"\"\"\n",
    "    \n",
    "    context = dspy.InputField(prefix=\"Relevant facts: \",desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField(prefix=\"Question: \")\n",
    "    answer = dspy.OutputField(prefix=\"Answer\",desc=\"answer in detail from the provided context\")\n",
    "    result: bool = dspy.OutputField(prefix=\"Result: \",desc=\"Answer to the question from either yes, no or maybe.\")\n",
    "\n",
    "class WikipediaGenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions in detail based on the context.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField(desc=\"question that needs to be answered\")\n",
    "    answer = dspy.OutputField(desc=\"answer in detail from the provided context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DSP_CACHEBOOL'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG:\n",
    "    def __init__(self,dataset_name:str,decoding_type:str,format_or_not,checkpoint,rank) -> None:\n",
    "        self.zipped_elem = question_answer_pair(dataset_name,decoding_type,format_or_not,checkpoint,rank)\n",
    "        if dataset_name == \"pubmed\":\n",
    "            self.retriever = pubmed_bm25_retriever\n",
    "            self.LLManswer = dspy.Predict(PubMedGenerateAnswer)\n",
    "        elif dataset_name == \"wikipedia\":\n",
    "            self.retriever = wiki_bm25_retriever\n",
    "            self.LLManswer = dspy.Predict(WikipediaGenerateAnswer)\n",
    "\n",
    "    def __call__(self,*args,**kwargs):\n",
    "        return self.forward(*args,**kwargs)\n",
    "    \n",
    "    def forward(self):\n",
    "        \n",
    "        for ques,mod_hyde_ans in self.zipped_elem:\n",
    "            print(ques)\n",
    "            print(mod_hyde_ans)\n",
    "            bm25_docs = pubmed_bm25_retriever.invoke(mod_hyde_ans)\n",
    "            context = \" \".join([ctx.page_content for ctx in bm25_docs])\n",
    "            final_answer = self.LLManswer(context=context,question=ques)\n",
    "            i+=1\n",
    "        return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = RAG(\"wikipedia\",\"nucleus\",True,'1662','32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airport is located in Maine, Sacramento International Airport or Knox County Regional Airport\n",
      "\n",
      ". The airport is served by US Airways and United Airlines; it is used by 30 airlines worldwide and with an average in flight schedule of over 400 flights daily.\n",
      "In 2003, the International Airport Authority of San Francisco voted to add a third runway to San Francisco International Airport with an extension, approximately 22 miles (35 km) long, to the existing runway I-510. The proposal was approved by the Board\n",
      "\n",
      "Peter Hobbs founded the company that is based in what town in Manchester\n",
      "\n",
      "\n",
      "?\n",
      "He is best known for being a bass guitar player for the rock band The Clash in 1981. The Clash were formed in London in 1977, led by singer Billy Gibbons and guitarist Mick Jagger. They were known for their progressive rock sound and later, their punk and grunge-influenced sound. The Clash were among the pioneers of the British new wave music. They formed a quartet in 1980 that was\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ans = rag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer=\"I'm sorry, but the provided context does not contain any information related to Peter Hobbs founding a company based in a town in Manchester.\"\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
